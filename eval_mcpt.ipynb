{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get_reader_writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/workspace/frames/val/scene_042/camera09/NIA_MTMDC_s42_c09_am_sunny_fall_0000.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reader_writer(source):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = {\n",
    "        # Val\n",
    "        'scene_042': sorted([os.path.join('/workspace/frames/val/scene_042', p) for p in os.listdir('/workspace/frames/val/scene_042')]),}\n",
    "sources['scene_042']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# src_handlers = [get_reader_writer(s) for s in sources['scene_042']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = '/workspace/frames/val/scene_042/camera09'\n",
    "src_paths = sorted(os.listdir(source),  key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "src_paths = [os.path.join(source, s) for s in src_paths]\n",
    "src_paths[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VideoWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(src_paths[0])\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detection model initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detection = YOLO('yolov8x.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pose estimation initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmpose.apis import init_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pose estimation initialize\n",
    "config_file = '/mmpose/configs/body_2d_keypoint/rtmpose/crowdpose/rtmpose-m_8xb64-210e_crowdpose-256x192.py'\n",
    "checkpoint_file = 'https://download.openmmlab.com/mmpose/v1/projects/rtmposev1/rtmpose-m_simcc-crowdpose_pt-aic-coco_210e-256x192-e6192cac_20230224.pth'\n",
    "pose = init_model(config_file, checkpoint_file, device='cuda:0')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "        'max_batch_size' : 32,  # maximum input batch size of reid model\n",
    "        'track_buffer' : 150,  # the frames for keep lost tracks\n",
    "        'with_reid' : True,  # whether to use reid model's out feature map at first association\n",
    "        'sct_appearance_thresh' : 0.4,  # threshold of appearance feature cosine distance when do single-cam tracking\n",
    "        'sct_euclidean_thresh' : 0.1,  # threshold of euclidean distance when do single-cam tracking\n",
    "\n",
    "        'clt_appearance_thresh' : 0.35,  # threshold of appearance feature cosine distance when do multi-cam clustering\n",
    "        'clt_euclidean_thresh' : 0.3,  # threshold of euclidean distance when do multi-cam clustering\n",
    "\n",
    "        'mct_appearance_thresh' : 0.4,  # threshold of appearance feature cosine distance when do cluster tracking (not important)\n",
    "\n",
    "        'frame_rate' : 30,  # your video(camera)'s fps\n",
    "        'write_vid' : False,  # write result to video\n",
    "        }\n",
    "\n",
    "conf_thres=0.1\n",
    "iou_thres=0.45\n",
    "\n",
    "scenes = ['scene_042']\n",
    "scene = scenes[0]\n",
    "perspective=scene\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = {\n",
    "        'scene_042': sorted([os.path.join('/workspace/frames/val/scene_042', p) for p in os.listdir('/workspace/frames/val/scene_042')]),\n",
    "}\n",
    "\n",
    "sources = sources[scene]\n",
    "sources\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## trackers initialize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackers.botsort.bot_sort import BoTSORT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trackers = []\n",
    "for i in range(len(sources)):\n",
    "    trackers.append(BoTSORT(track_buffer=args['track_buffer'], max_batch_size=args['max_batch_size'], \n",
    "                        appearance_thresh=args['sct_appearance_thresh'], euc_thresh=args['sct_euclidean_thresh'],))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## perspective transform initialize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from perspective_transform.model import PerspectiveTransform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibration_position = {\n",
    "    # Val\n",
    "    \"scene_042\": sorted([str(p) for p in Path(\"/workspace/videos/val/scene_042\").glob(\"**/calibration.json\")])\n",
    "}\n",
    "\n",
    "calibration_position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrations = calibration_position[perspective]\n",
    "perspective_transforms = [PerspectiveTransform(c) for c in calibrations]\n",
    "perspective_transforms\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## id_distributor and multi-camera tracker initialize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trackers.multicam_tracker.cluster_track import MCTracker\n",
    "from trackers.multicam_tracker.clustering import Clustering, ID_Distributor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = Clustering(appearance_thresh=args['clt_appearance_thresh'], euc_thresh=args['clt_euclidean_thresh'],\n",
    "                        match_thresh=0.8)\n",
    "mc_tracker = MCTracker(appearance_thresh=args['mct_appearance_thresh'], match_thresh=0.8, scene=scene)\n",
    "id_distributor = ID_Distributor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get source imgs, video writers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reader_writer(source):\n",
    "    src_paths = sorted(os.listdir(source),  key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0]))\n",
    "    src_paths = [os.path.join(source, s) for s in src_paths]\n",
    "\n",
    "    fps = 30\n",
    "    wi, he = 1920, 1080\n",
    "    os.makedirs('output_videos/' + source.split('/')[-2], exist_ok=True)\n",
    "    # dst = 'output_videos/' + source.replace('/','').replace('.','') + '.mp4'\n",
    "    dst = f\"output_videos/{source.split('/')[-2]}/\" + source.split('/')[-3] + '_' + source.split('/')[-2] + source.split('/')[-1] + '.mp4'\n",
    "    video_writer = cv2.VideoWriter(dst, cv2.VideoWriter_fourcc(*'mp4v'), fps, (wi, he))\n",
    "    print(f\"{source}'s total frames: {len(src_paths)}\")\n",
    "\n",
    "    return [src_paths, video_writer]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_handlers = [get_reader_writer(s) for s in sources]\n",
    "results_lists = [[] for i in range(len(sources))]  # make empty lists to store tracker outputs in MOT Format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_frames = max([len(s[0]) for s in src_handlers])  # 321\n",
    "cur_frame = 1\n",
    "stop = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# While loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## first, run trackers each frame independently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "components = zip(src_handlers, trackers, perspective_transforms, results_lists)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(img_paths, writer), tracker, perspective_transform, result_list = next(components)\n",
    "print(f\"len img_paths: {len(img_paths)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = img_paths.pop(0)\n",
    "img = cv2.imread(img_path)\n",
    "plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run detection model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = detection(img, conf=conf_thres, iou=iou_thres, classes=0)\n",
    "dets = results[0].boxes.data.cpu().numpy()  # [(x1, y1, x2, y2, conf, cls), ...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(cv2.cvtColor(results[0].plot(), cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "online_targets, new_ratio = tracker.update(dets, img, img_path, pose)  # [bot_sort.Strack]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(online_targets))\n",
    "type(online_targets[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run perspective transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perspective_transform.run(tracker, new_ratio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## assign temporal global_id to each track for multi-camera tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tracker.tracked_stracks:\n",
    "    t.t_global_id = id_distributor.assign_id()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(imgs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STrack status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in tracker.tracked_stracks:\n",
    "    print(t.is_activated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker.lost_stracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.track_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmpose.apis import inference_topdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import numpy as np\n",
    "colors = seaborn.color_palette(n_colors= 80)\n",
    "colors = np.array(colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pose_input = dets[:, :4]\n",
    "pose_results = inference_topdown(pose, img, pose_input, bbox_format=\"xyxy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def visualize_pose_results(results, img):\n",
    "    img = img.copy()\n",
    "    for i, result in enumerate(results):\n",
    "        # Extract predicted keypoints and bboxes\n",
    "        pred_instances = result.pred_instances\n",
    "        keypoints = pred_instances.keypoints[0] if pred_instances.keypoints is not None else []\n",
    "        bboxes = pred_instances.bboxes[0] if pred_instances.bboxes is not None else []\n",
    "\n",
    "        # Draw the bounding box\n",
    "        if len(bboxes) == 4:\n",
    "            x1, y1, x2, y2 = bboxes.astype(int)\n",
    "            cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "        # Draw keypoints\n",
    "        for kp_index, kp in enumerate(keypoints):\n",
    "            x, y = kp.astype(int)\n",
    "            cv2.circle(img, (x, y), 3, (255, 0, 0), -1)\n",
    "            cv2.putText(img, f\"{kp_index}\", (x, y), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 255), 1)\n",
    "\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Pose Visualization\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def visualize_pose_with_connections(results, img, draw_connect=False):\n",
    "    # Define the keypoint connections for CrowdPose\n",
    "    connections = [\n",
    "        (13, 6), (6, 8), (8, 10),  # Left leg\n",
    "        (13, 7), (7, 9), (9, 11),  # Right leg\n",
    "        (13, 1), (1, 3), (3, 5), # Right arm\n",
    "        (13, 0), (0, 2), (2, 4), # Left arm\n",
    "        (12, 13),# Neck to head\n",
    "    ]\n",
    "    img = img.copy()\n",
    "    for i, result in enumerate(results):\n",
    "        # Extract predicted keypoints\n",
    "        pred_instances = result.pred_instances\n",
    "        keypoints = pred_instances.keypoints[0] if pred_instances.keypoints is not None else []\n",
    "\n",
    "        # Draw keypoints\n",
    "        for kp in keypoints:\n",
    "            x, y = kp[:2].astype(int)\n",
    "            cv2.circle(img, (x, y), 5, (255, 0, 0), -1)\n",
    "\n",
    "        if draw_connect:\n",
    "            # Draw connections\n",
    "            for start, end in connections:\n",
    "                if len(keypoints) > max(start, end):  # Ensure indices are valid\n",
    "                    x1, y1 = keypoints[start, :2].astype(int)\n",
    "                    x2, y2 = keypoints[end, :2].astype(int)\n",
    "                    cv2.line(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "    # Display the image\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Pose Visualization {i+1}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(dets, img, colors, pose, pose_result, cur_frame):\n",
    "    m = 2\n",
    "    if len(dets) == 0:\n",
    "        return img\n",
    "\n",
    "    # keypoints = [p['keypoints'][:,:2] for p in pose_result]\n",
    "    # scores = [p['keypoints'][:,2] for p in pose_result]\n",
    "    keypoints = pose_result[0].pred_instances.keypoints\n",
    "    scores = pose_results[0].pred_instances.keypoint_scores\n",
    "    img = visualize_kpt(img, keypoints, scores, thr=0.3)\n",
    "            \n",
    "    for obj in dets:\n",
    "        score = obj[4]\n",
    "        track_id = int(obj[5])\n",
    "        # len_feats = ' ' if obj[6] == 50 else obj[6]\n",
    "        len_feats = ' '\n",
    "        x0, y0, x1, y1 = int(obj[0]), int(obj[1]), int(obj[2]), int(obj[3])\n",
    "\n",
    "        color = (colors[track_id%80] * 255).astype(np.uint8).tolist()\n",
    "        text = '{} : {:.1f}% | {}'.format(track_id, score * 100, len_feats)\n",
    "        txt_color = (0, 0, 0) if np.mean(colors[track_id%80]) > 0.5 else (255, 255, 255)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        txt_size = cv2.getTextSize(text, font, 0.4*m, 1*m)[0]\n",
    "        cv2.rectangle(img, (x0, y0), (x1, y1), color, 2)\n",
    "\n",
    "        txt_bk_color = (colors[track_id%80] * 255 * 0.7).astype(np.uint8).tolist()\n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (x0, y0 - 1),\n",
    "            (x0 + txt_size[0] + 1, y0 - int(1.5*txt_size[1])),\n",
    "            txt_bk_color,\n",
    "            -1\n",
    "        )\n",
    "        cv2.putText(img, text, (x0, y0 - txt_size[1]), font, 0.4*m, txt_color, thickness=1*m)\n",
    "    \n",
    "    return img\n",
    "\n",
    "def visualize_kpt(img,\n",
    "              keypoints,\n",
    "              scores,\n",
    "              thr=0.3) -> np.ndarray:\n",
    "\n",
    "    skeleton = [\n",
    "        [12, 13], [13, 0], [13, 1], [0, 1], [6, 7], [0, 2], [2, 4], \n",
    "        [1, 3], [3, 5], [0, 6], [1, 7], [6, 8], [8, 10], [7, 9], [9, 11]\n",
    "    ]\n",
    "    palette = [[51, 153, 255], [0, 255, 0], [255, 128, 0], [255, 255, 255],\n",
    "               [255, 153, 255], [102, 178, 255], [255, 51, 51]]\n",
    "    link_color = [3, 3, 3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2]\n",
    "    point_color = [0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 3, 3]\n",
    "\n",
    "    # draw keypoints and skeleton\n",
    "    for kpts, score in zip(keypoints, scores):\n",
    "        for kpt, color in zip(kpts, point_color):\n",
    "            cv2.circle(img, tuple(kpt.astype(np.int32)), 2, palette[color], 2,\n",
    "                       cv2.LINE_AA)\n",
    "        for (u, v), color in zip(skeleton, link_color):\n",
    "            if score[u] > thr and score[v] > thr:\n",
    "                cv2.line(img, tuple(kpts[u].astype(np.int32)),\n",
    "                         tuple(kpts[v].astype(np.int32)), palette[color], 1,\n",
    "                         cv2.LINE_AA)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_img = visualize(dets, img, colors, pose, pose_results, cur_frame)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_pose_with_connections(pose_results, cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB), draw_connect=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# second, run multi-camera tracker using above trackers results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = clustering.update(trackers, cur_frame, scene)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "list(combinations([1,2,3], 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_tracker.update(trackers, groups)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering.update_using_mctracker(trackers, mc_tracker)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# third, run cluster self-refinements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cur_frame)\n",
    "if cur_frame % 5 == 0:\n",
    "    mc_tracker.refinement_clusters()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# update result lists using updated trackers\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_result_lists_testset(trackers, result_lists, frame_id, cam_ids, scene):\n",
    "    results_frame = [[] for i in range(len(result_lists))]\n",
    "    results_frame_feat = []\n",
    "    for tracker, result_frame, result_list, cam_id in zip(trackers, results_frame, result_lists, cam_ids):\n",
    "        for track in tracker.tracked_stracks:\n",
    "            if track.global_id < 0: continue\n",
    "            result = {\n",
    "                'cam_id': int(cam_id),\n",
    "                'frame_id': frame_id,\n",
    "                'track_id': track.global_id,\n",
    "                'sct_track_id': track.track_id,\n",
    "                'tlwh': list(map(lambda x: int(x), track.tlwh.tolist())),\n",
    "                '2d_coord': track.location[0].tolist()\n",
    "            }\n",
    "            result_ = list(result.values())\n",
    "            result_list.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_ids = [9, 10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_result_lists_testset(trackers, results_lists, cur_frame, cam_ids, scene)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"video frame ({cur_frame}/{total_frames})\")\n",
    "cur_frame += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_lists\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_kpt(img,\n",
    "              keypoints,\n",
    "              scores,\n",
    "              thr=0.3) -> np.ndarray:\n",
    "\n",
    "    skeleton = [\n",
    "        [12, 13], [13, 0], [13, 1], [0, 1], [6, 7], [0, 2], [2, 4], \n",
    "        [1, 3], [3, 5], [0, 6], [1, 7], [6, 8], [8, 10], [7, 9], [9, 11]\n",
    "    ]\n",
    "    palette = [[51, 153, 255], [0, 255, 0], [255, 128, 0], [255, 255, 255],\n",
    "               [255, 153, 255], [102, 178, 255], [255, 51, 51]]\n",
    "    link_color = [3, 3, 3, 0, 1, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2]\n",
    "    point_color = [0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 2, 3, 3]\n",
    "\n",
    "    # draw keypoints and skeleton\n",
    "    for kpts, score in zip(keypoints, scores):\n",
    "        for kpt, color in zip(kpts, point_color):\n",
    "            cv2.circle(img, tuple(kpt.astype(np.int32)), 2, palette[color], 2,\n",
    "                       cv2.LINE_AA)\n",
    "        for (u, v), color in zip(skeleton, link_color):\n",
    "            if score[u] > thr and score[v] > thr:\n",
    "                cv2.line(img, tuple(kpts[u].astype(np.int32)),\n",
    "                         tuple(kpts[v].astype(np.int32)), palette[color], 1,\n",
    "                         cv2.LINE_AA)\n",
    "\n",
    "    return img\n",
    "\n",
    "def visualize(dets, img, colors, pose_result=None):\n",
    "    m = 2\n",
    "    if len(dets) == 0:\n",
    "        return img\n",
    "    if pose_result is not None:\n",
    "        keypoints = [p['keypoints'][:,:2] for p in pose_result]\n",
    "        scores = [p['keypoints'][:,2] for p in pose_result]\n",
    "        img = visualize_kpt(img, keypoints, scores, thr=0.3)\n",
    "            \n",
    "    for obj in dets:\n",
    "        score = obj[4]\n",
    "        track_id = int(obj[5])\n",
    "        len_feats = ' ' if obj[6] == 50 else obj[6]\n",
    "        x0, y0, x1, y1 = int(obj[0]), int(obj[1]), int(obj[2]), int(obj[3])\n",
    "\n",
    "        color = (colors[track_id%80] * 255).astype(np.uint8).tolist()\n",
    "        text = '{} : {:.1f}% | {}'.format(track_id, score * 100, len_feats)\n",
    "        txt_color = (0, 0, 0) if np.mean(colors[track_id%80]) > 0.5 else (255, 255, 255)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "        txt_size = cv2.getTextSize(text, font, 0.4*m, 1*m)[0]\n",
    "        cv2.rectangle(img, (x0, y0), (x1, y1), color, 2)\n",
    "\n",
    "        txt_bk_color = (colors[track_id%80] * 255 * 0.7).astype(np.uint8).tolist()\n",
    "        cv2.rectangle(\n",
    "            img,\n",
    "            (x0, y0 - 1),\n",
    "            (x0 + txt_size[0] + 1, y0 - int(1.5*txt_size[1])),\n",
    "            txt_bk_color,\n",
    "            -1\n",
    "        )\n",
    "        cv2.putText(img, text, (x0, y0 - txt_size[1]), font, 0.4*m, txt_color, thickness=1*m)\n",
    "    \n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gid_2_lenfeats = {}\n",
    "for track in mc_tracker.tracked_mtracks + mc_tracker.lost_mtracks:\n",
    "    if track.is_activated:\n",
    "        gid_2_lenfeats[track.track_id] = len(track.features)\n",
    "    else:\n",
    "        gid_2_lenfeats[-2] = len(track.features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_imgs= []\n",
    "for tracker, img in zip(trackers, imgs):\n",
    "    outputs = [t.tlbr.tolist() + [t.score, t.global_id, gid_2_lenfeats.get(t.global_id, -1)] for t in tracker.tracked_stracks]\n",
    "    img = visualize(outputs, img, colors)\n",
    "    results_imgs.append(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = np.vstack(results_imgs)\n",
    "plt.figure(figsize=(6, 8))\n",
    "plt.imshow(cv2.cvtColor(res, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
